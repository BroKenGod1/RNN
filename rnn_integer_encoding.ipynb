{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0biyXtMHprUt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['hello',\n",
        "'its me ',\n",
        "'I was wondering if',\n",
        "'after all these years you would like to meet',\n",
        "'To go over everything',\n",
        "'They say that time',\n",
        "' supposed to heal ya, but I has not  done much healing',\n",
        "'Hello, can you hear me'\n",
        "]"
      ],
      "metadata": {
        "id": "lzV6S6yOqB1Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "Tokenizer = Tokenizer(oov_token='<nothing>')"
      ],
      "metadata": {
        "id": "Q-QXNjqaqn3x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "JUDoFu4Eq4dh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggs2t0_MrR0q",
        "outputId": "78e028be-64e6-498a-94c8-84d1207bc005"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<nothing>': 1,\n",
              " 'to': 2,\n",
              " 'hello': 3,\n",
              " 'me': 4,\n",
              " 'i': 5,\n",
              " 'you': 6,\n",
              " 'its': 7,\n",
              " 'was': 8,\n",
              " 'wondering': 9,\n",
              " 'if': 10,\n",
              " 'after': 11,\n",
              " 'all': 12,\n",
              " 'these': 13,\n",
              " 'years': 14,\n",
              " 'would': 15,\n",
              " 'like': 16,\n",
              " 'meet': 17,\n",
              " 'go': 18,\n",
              " 'over': 19,\n",
              " 'everything': 20,\n",
              " 'they': 21,\n",
              " 'say': 22,\n",
              " 'that': 23,\n",
              " 'time': 24,\n",
              " 'supposed': 25,\n",
              " 'heal': 26,\n",
              " 'ya': 27,\n",
              " 'but': 28,\n",
              " 'has': 29,\n",
              " 'not': 30,\n",
              " 'done': 31,\n",
              " 'much': 32,\n",
              " 'healing': 33,\n",
              " 'can': 34,\n",
              " 'hear': 35}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tokenizer.texts_to_sequences(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YRsWwKjrV_m",
        "outputId": "876a2817-f83d-4821-d301-e09c1562c1b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3],\n",
              " [7, 4],\n",
              " [5, 8, 9, 10],\n",
              " [11, 12, 13, 14, 6, 15, 16, 2, 17],\n",
              " [2, 18, 19, 20],\n",
              " [21, 22, 23, 24],\n",
              " [25, 2, 26, 27, 28, 5, 29, 30, 31, 32, 33],\n",
              " [3, 34, 6, 35, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "6jBEDchrreti"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_sequences(Tokenizer.texts_to_sequences(docs),padding='post')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNM3I2EusCOz",
        "outputId": "8ebdc784-e5da-4f6c-d6cd-9becd220b500"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 7,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 5,  8,  9, 10,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [11, 12, 13, 14,  6, 15, 16,  2, 17,  0,  0],\n",
              "       [ 2, 18, 19, 20,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [21, 22, 23, 24,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [25,  2, 26, 27, 28,  5, 29, 30, 31, 32, 33],\n",
              "       [ 3, 34,  6, 35,  4,  0,  0,  0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4w7KluasE-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}